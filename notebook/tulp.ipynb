{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "# Load the list of poetry titles\n",
    "poetry_file_path = 'filtered_texts_1600_1700.csv' \n",
    "df = pd.read_csv(poetry_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "707\n"
     ]
    }
   ],
   "source": [
    "filtered_df = df[(df['jaar'] >= 1610) & (df['jaar'] <= 1670)]\n",
    "print(len(filtered_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied poir001afbe01_01.xml to 17thcentury_files\n",
      "Copied rode001hert01_01.xml to 17thcentury_files\n",
      "Copied stal001extr01_01.xml to 17thcentury_files\n",
      "Copied jonc006hede01_01.xml to 17thcentury_files\n",
      "Copied heyn003wegw01_01.xml to 17thcentury_files\n",
      "Copied maer005stic01_01.xml to 17thcentury_files\n",
      "Copied pass004spie01_01.xml to 17thcentury_files\n",
      "Copied camp001uytb01_01.xml to 17thcentury_files\n",
      "Copied stal001evan01_01.xml to 17thcentury_files\n",
      "Copied ocke003heme01_01.xml to 17thcentury_files\n",
      "Copied ruys008flor01_01.xml to 17thcentury_files\n",
      "Copied crus001epig01_01.xml to 17thcentury_files\n",
      "Copied thie008scha01_01.xml to 17thcentury_files\n",
      "Copied haef001lust01_01.xml to 17thcentury_files\n",
      "Copied gabb001lykt01_01.xml to 17thcentury_files\n",
      "Copied hube012psal01_01.xml to 17thcentury_files\n",
      "Copied bolo001ghee01_01.xml to 17thcentury_files\n",
      "Copied merw001uyth01_01.xml to 17thcentury_files\n",
      "Copied roch007natu01_01.xml to 17thcentury_files\n",
      "Copied boel009onee01_01.xml to 17thcentury_files\n",
      "Copied momm004brab02_01.xml to 17thcentury_files\n",
      "Copied mule001heme01_01.xml to 17thcentury_files\n",
      "Copied nieu001jeru01_01.xml to 17thcentury_files\n",
      "Copied hard001denv01_01.xml to 17thcentury_files\n",
      "Copied star001timb01_01.xml to 17thcentury_files\n",
      "Copied nieu001soph03_01.xml to 17thcentury_files\n",
      "Copied krul001verm01_01.xml to 17thcentury_files\n",
      "Copied born006gees01_01.xml to 17thcentury_files\n",
      "Copied smet025oude01_01.xml to 17thcentury_files\n",
      "Copied ampz001west01_01.xml to 17thcentury_files\n",
      "Copied heyn003embl01_01.xml to 17thcentury_files\n",
      "Copied koer001bloe01_01.xml to 17thcentury_files\n",
      "Copied spey001syon02_01.xml to 17thcentury_files\n",
      "Copied krul001vonn01_01.xml to 17thcentury_files\n",
      "Copied koer001tnie01_01.xml to 17thcentury_files\n",
      "Copied goos015nieu01_01.xml to 17thcentury_files\n",
      "Copied ooij001haer01_01.xml to 17thcentury_files\n",
      "Copied bosc015kons01_01.xml to 17thcentury_files\n",
      "Copied veen033kroo01_01.xml to 17thcentury_files\n",
      "Copied star001drie01_01.xml to 17thcentury_files\n",
      "Copied putm012putm01_01.xml to 17thcentury_files\n",
      "Copied carp002verh01_01.xml to 17thcentury_files\n",
      "Copied star001dara02_01.xml to 17thcentury_files\n",
      "Copied zach001bruy01_01.xml to 17thcentury_files\n",
      "Copied stal001room01_01.xml to 17thcentury_files\n",
      "Copied duis001echt01_01.xml to 17thcentury_files\n",
      "Copied wits010stic02_01.xml to 17thcentury_files\n",
      "Copied huyg001mome02_01.xml to 17thcentury_files\n",
      "Copied meij001lmei01_01.xml to 17thcentury_files\n",
      "Copied make001troo02_01.xml to 17thcentury_files\n",
      "Copied baro004leyt01_01.xml to 17thcentury_files\n",
      "Copied lope001dull01_01.xml to 17thcentury_files\n",
      "Copied gouw004erat01_01.xml to 17thcentury_files\n",
      "Copied elst005ghee01_01.xml to 17thcentury_files\n",
      "Copied mand001guld02_01.xml to 17thcentury_files\n",
      "Copied fore024refe01_01.xml to 17thcentury_files\n",
      "Copied goed012meta02_01.xml to 17thcentury_files\n",
      "Copied over001psal01_01.xml to 17thcentury_files\n",
      "Copied brun001gron01_01.xml to 17thcentury_files\n",
      "Copied houw001para01_01.xml to 17thcentury_files\n",
      "Copied rode001egle01_01.xml to 17thcentury_files\n",
      "Copied harm001suyv01_01.xml to 17thcentury_files\n",
      "Copied poir001pelg01_01.xml to 17thcentury_files\n",
      "Copied vaen001embl01_01.xml to 17thcentury_files\n",
      "Copied nier007opre01_01.xml to 17thcentury_files\n",
      "Copied gilb007lief01_01.xml to 17thcentury_files\n",
      "Copied nieu001clau01_01.xml to 17thcentury_files\n",
      "Copied dros028scho01_01.xml to 17thcentury_files\n",
      "Copied camp001drka01_01.xml to 17thcentury_files\n",
      "Copied orle001besc01_01.xml to 17thcentury_files\n",
      "Copied rode001keys02_01.xml to 17thcentury_files\n",
      "Copied mech003ghee01_01.xml to 17thcentury_files\n",
      "Copied sent002nieu01_01.xml to 17thcentury_files\n",
      "Copied buit010bloe01_01.xml to 17thcentury_files\n",
      "Copied beve001scha01_01.xml to 17thcentury_files\n",
      "Copied sonn003basu01_01.xml to 17thcentury_files\n",
      "Copied wael001brvy01_01.xml to 17thcentury_files\n",
      "Copied koni001acha01_01.xml to 17thcentury_files\n",
      "Copied hoof001hend02_01.xml to 17thcentury_files\n",
      "Copied brun001davi01_01.xml to 17thcentury_files\n",
      "Copied wesb002haer01_01.xml to 17thcentury_files\n",
      "Copied make001scha02_01.xml to 17thcentury_files\n",
      "Copied vond001maeg04_01.xml to 17thcentury_files\n",
      "Copied veen010over01_01.xml to 17thcentury_files\n",
      "Copied bien002prof02_01.xml to 17thcentury_files\n",
      "Copied vond001pala01_01.xml to 17thcentury_files\n",
      "Copied vond001pete01_01.xml to 17thcentury_files\n",
      "Copied bors001stra01_01.xml to 17thcentury_files\n",
      "Copied roel018biro03_01.xml to 17thcentury_files\n",
      "Copied goid001chro01_01.xml to 17thcentury_files\n",
      "Copied donc007besc01_01.xml to 17thcentury_files\n",
      "Copied noot008jeug01_01.xml to 17thcentury_files\n",
      "Copied stal001guld02_01.xml to 17thcentury_files\n",
      "Copied vinc009nieu01_01.xml to 17thcentury_files\n",
      "Copied teyl001devo01_01.xml to 17thcentury_files\n",
      "Copied rula001saty01_01.xml to 17thcentury_files\n",
      "Copied vivr001dial02_01.xml to 17thcentury_files\n",
      "Copied jaco009scha01_01.xml to 17thcentury_files\n",
      "Copied heyn003embl03_01.xml to 17thcentury_files\n",
      "Copied revi001clps01_01.xml to 17thcentury_files\n",
      "Copied vond001hier01_01.xml to 17thcentury_files\n",
      "Copied mech003cloo01_01.xml to 17thcentury_files\n",
      "Copied camp001stic01_01.xml to 17thcentury_files\n",
      "Copied samb001gees01_01.xml to 17thcentury_files\n",
      "Copied gera044sedi01_01.xml to 17thcentury_files\n",
      "Copied hoof002jans02_01.xml to 17thcentury_files\n",
      "Copied vict001goli01_01.xml to 17thcentury_files\n",
      "Copied koni001sims01_01.xml to 17thcentury_files\n",
      "Copied krul001amst01_01.xml to 17thcentury_files\n",
      "Copied vond001luci01_01.xml to 17thcentury_files\n",
      "Copied hoof002styv01_01.xml to 17thcentury_files\n",
      "Copied hard001godd02_01.xml to 17thcentury_files\n",
      "Copied vrie047uytg01_01.xml to 17thcentury_files\n",
      "Copied baud002afbe01_01.xml to 17thcentury_files\n",
      "Copied haer002lied01_01.xml to 17thcentury_files\n",
      "Copied nieu001poem01_01.xml to 17thcentury_files\n",
      "Copied breu004lust01_01.xml to 17thcentury_files\n",
      "Copied baud004edip01_01.xml to 17thcentury_files\n",
      "Copied cole001lust01_01.xml to 17thcentury_files\n",
      "Copied cats001maec01_01.xml to 17thcentury_files\n",
      "Copied vond001jose05_01.xml to 17thcentury_files\n",
      "Copied mand001beth01_01.xml to 17thcentury_files\n",
      "Copied oost026gelo01_01.xml to 17thcentury_files\n",
      "Copied rhij002vreu02_01.xml to 17thcentury_files\n",
      "Copied bour004desw01_01.xml to 17thcentury_files\n",
      "Copied fort007gees01_01.xml to 17thcentury_files\n",
      "Copied smid018lyde02_01.xml to 17thcentury_files\n",
      "Copied oost026ryme01_01.xml to 17thcentury_files\n",
      "Copied else006lacc01_01.xml to 17thcentury_files\n",
      "Copied kolm001leve01_01.xml to 17thcentury_files\n",
      "Copied krul001rosi01_01.xml to 17thcentury_files\n",
      "Copied swae006sing01_01.xml to 17thcentury_files\n",
      "Copied rhij002vreu04_01.xml to 17thcentury_files\n",
      "Copied pute001comu01_01.xml to 17thcentury_files\n",
      "Copied kalb001muli01_01.xml to 17thcentury_files\n",
      "Copied clae030rijp02_01.xml to 17thcentury_files\n",
      "Copied jonc006rose01_01.xml to 17thcentury_files\n",
      "Copied heem001pubo01_01.xml to 17thcentury_files\n",
      "Copied make001denh01_01.xml to 17thcentury_files\n",
      "Copied gerr049hist01_01.xml to 17thcentury_files\n",
      "Copied zasy001borg01_01.xml to 17thcentury_files\n",
      "Copied baud002morg01_01.xml to 17thcentury_files\n",
      "Copied ampz001klae01_01.xml to 17thcentury_files\n",
      "Copied hoof001embl02_01.xml to 17thcentury_files\n",
      "Copied vond001pasc02_01.xml to 17thcentury_files\n",
      "Copied vloe003ghee01_01.xml to 17thcentury_files\n",
      "Copied ampz001nasz01_01.xml to 17thcentury_files\n",
      "Copied mayv001verm01_01.xml to 17thcentury_files\n",
      "Copied popp007hist01_01.xml to 17thcentury_files\n",
      "Copied swam001hist01_01.xml to 17thcentury_files\n",
      "Copied brun001embl02_01.xml to 17thcentury_files\n",
      "Copied rode001keys01_01.xml to 17thcentury_files\n",
      "Copied goed012meta03_01.xml to 17thcentury_files\n",
      "Copied groo001chri03_01.xml to 17thcentury_files\n",
      "Copied font031ario01_01.xml to 17thcentury_files\n",
      "Copied meer040como01_01.xml to 17thcentury_files\n",
      "Copied goed012meta01_01.xml to 17thcentury_files\n",
      "Copied gerr003nieu01_01.xml to 17thcentury_files\n",
      "Copied gelr003triu01_01.xml to 17thcentury_files\n",
      "Copied nieu001aegy01_01.xml to 17thcentury_files\n",
      "Copied rode001keys03_01.xml to 17thcentury_files\n",
      "Copied breu004cupi01_01.xml to 17thcentury_files\n",
      "Copied orle001vers01_01.xml to 17thcentury_files\n",
      "Copied poir001duyf01_01.xml to 17thcentury_files\n",
      "Copied drie002ench01_01.xml to 17thcentury_files\n",
      "Copied brun004davi01_01.xml to 17thcentury_files\n",
      "Copied magi007kooc02_01.xml to 17thcentury_files\n",
      "Copied hein001cont01_01.xml to 17thcentury_files\n",
      "Copied verm047rond01_01.xml to 17thcentury_files\n",
      "Copied well004verm01_01.xml to 17thcentury_files\n",
      "Copied cats001sile01_01.xml to 17thcentury_files\n",
      "Copied leuv001thea01_01.xml to 17thcentury_files\n",
      "Copied cole001nieu01_01.xml to 17thcentury_files\n",
      "Copied soet007kley01_01.xml to 17thcentury_files\n",
      "Copied leeu035chri01_01.xml to 17thcentury_files\n",
      "Copied hout009test01_01.xml to 17thcentury_files\n",
      "Copied rode001rodo01_01.xml to 17thcentury_files\n",
      "Copied jenn003ghee01_01.xml to 17thcentury_files\n",
      "Copied deut002kley01_01.xml to 17thcentury_files\n",
      "Copied krul001eerl01_01.xml to 17thcentury_files\n",
      "Copied eemb001haer01_01.xml to 17thcentury_files\n",
      "Copied bols002duyf02_01.xml to 17thcentury_files\n",
      "Copied dyck014oude01_01.xml to 17thcentury_files\n",
      "Copied swae006sing03_01.xml to 17thcentury_files\n",
      "Copied cats001klag01_01.xml to 17thcentury_files\n",
      "Copied brau007scha01_01.xml to 17thcentury_files\n",
      "Copied bred001gees01_01.xml to 17thcentury_files\n",
      "Copied hani001beve01_01.xml to 17thcentury_files\n",
      "Copied quin005holl01_01.xml to 17thcentury_files\n",
      "Copied bred001spaa09_01.xml to 17thcentury_files\n",
      "Copied kolm001batt01_01.xml to 17thcentury_files\n",
      "Copied boxh002embl02_01.xml to 17thcentury_files\n",
      "Copied vond001elek01_01.xml to 17thcentury_files\n",
      "Copied nieu001salo01_01.xml to 17thcentury_files\n",
      "Copied borc002brus01_01.xml to 17thcentury_files\n",
      "Copied vaer010haar01_01.xml to 17thcentury_files\n",
      "Copied mijl001ling01_01.xml to 17thcentury_files\n",
      "Copied leuv001amor01_01.xml to 17thcentury_files\n",
      "Copied vaen001quin01_01.xml to 17thcentury_files\n",
      "Copied vaen001amor02_01.xml to 17thcentury_files\n",
      "Copied ampz001rijm01_01.xml to 17thcentury_files\n",
      "Copied cour001inte01_01.xml to 17thcentury_files\n",
      "Copied hugo001piad01_01.xml to 17thcentury_files\n",
      "Copied stal001vrou01_01.xml to 17thcentury_files\n",
      "Copied cats001houw01_01.xml to 17thcentury_files\n",
      "Copied vlee002ryme01_01.xml to 17thcentury_files\n",
      "Copied juni001schi01_01.xml to 17thcentury_files\n",
      "Copied eemb001soph01_01.xml to 17thcentury_files\n",
      "Copied cloc001groo02_01.xml to 17thcentury_files\n",
      "Copied haef004para02_01.xml to 17thcentury_files\n",
      "Copied west001davi01_01.xml to 17thcentury_files\n",
      "Copied hond001dape02_01.xml to 17thcentury_files\n",
      "Copied vena001vert01_01.xml to 17thcentury_files\n",
      "Copied bors001denb01_01.xml to 17thcentury_files\n",
      "Copied rode001casa01_01.xml to 17thcentury_files\n",
      "Copied veen010zinn01_01.xml to 17thcentury_files\n",
      "Copied mayv001scha01_01.xml to 17thcentury_files\n",
      "Copied yser001triu01_01.xml to 17thcentury_files\n",
      "Copied haef001scho01_01.xml to 17thcentury_files\n",
      "Copied brun001prov01_01.xml to 17thcentury_files\n",
      "Copied bode001goud01_01.xml to 17thcentury_files\n",
      "Copied vrol014matr01_01.xml to 17thcentury_files\n",
      "Copied meer017gees01_01.xml to 17thcentury_files\n",
      "Copied brun001clda01_01.xml to 17thcentury_files\n",
      "Copied pels017tlof01_01.xml to 17thcentury_files\n",
      "Copied hame003jour01_01.xml to 17thcentury_files\n",
      "Copied stey002geve01_01.xml to 17thcentury_files\n",
      "Copied burg016gere02_01.xml to 17thcentury_files\n",
      "Copied scho188embl01_01.xml to 17thcentury_files\n",
      "Copied scha001spel01_01.xml to 17thcentury_files\n",
      "Copied lixb001heme02_01.xml to 17thcentury_files\n",
      "Copied stal001heme01_01.xml to 17thcentury_files\n",
      "Copied aker002clee01_01.xml to 17thcentury_files\n",
      "Copied poll013bruy01_01.xml to 17thcentury_files\n",
      "Copied smid018minn01_01.xml to 17thcentury_files\n",
      "Copied ling001apol01_01.xml to 17thcentury_files\n",
      "Copied ampz001hoog01_01.xml to 17thcentury_files\n",
      "Copied ques002lauw01_01.xml to 17thcentury_files\n",
      "Copied lubb003lijd01_01.xml to 17thcentury_files\n",
      "Copied zeve001poem01_01.xml to 17thcentury_files\n",
      "Copied heem007nede01_01.xml to 17thcentury_files\n",
      "Copied nieu001livi01_01.xml to 17thcentury_files\n",
      "Copied vond001gysb04_01.xml to 17thcentury_files\n",
      "Copied kerc001vand01_01.xml to 17thcentury_files\n",
      "Copied houw001deng01_01.xml to 17thcentury_files\n",
      "Copied sucq002wech01_01.xml to 17thcentury_files\n",
      "Copied fran115grou01_01.xml to 17thcentury_files\n",
      "Copied dubb003heli01_01.xml to 17thcentury_files\n",
      "Copied slui006psal01_01.xml to 17thcentury_files\n",
      "Copied stri015chao01_01.xml to 17thcentury_files\n",
      "Copied plat001dord01_01.xml to 17thcentury_files\n",
      "Copied brug061chri01_01.xml to 17thcentury_files\n",
      "Copied zoet001parn01_01.xml to 17thcentury_files\n",
      "Copied sout002nvch01_01.xml to 17thcentury_files\n",
      "Copied loem001ghee01_01.xml to 17thcentury_files\n",
      "Copied eras001kers03_01.xml to 17thcentury_files\n",
      "Copied cats001trou01_01.xml to 17thcentury_files\n",
      "Copied fyne001kley01_01.xml to 17thcentury_files\n",
      "Copied camp001stic02_01.xml to 17thcentury_files\n",
      "Copied para003prin02_01.xml to 17thcentury_files\n",
      "Copied scep002oude01_01.xml to 17thcentury_files\n",
      "Copied nieu001saul01_01.xml to 17thcentury_files\n",
      "Copied beer014ghee01_01.xml to 17thcentury_files\n",
      "Copied brun002wets01_01.xml to 17thcentury_files\n",
      "Copied verl023amst01_01.xml to 17thcentury_files\n",
      "Copied bien002hand01_01.xml to 17thcentury_files\n",
      "Copied bosc015poet01_01.xml to 17thcentury_files\n",
      "Copied hard001godd01_01.xml to 17thcentury_files\n",
      "Copied west001nieu01_01.xml to 17thcentury_files\n",
      "Copied ampz001besc01_01.xml to 17thcentury_files\n",
      "Copied joos025groo01_01.xml to 17thcentury_files\n",
      "Copied grie003spre01_01.xml to 17thcentury_files\n",
      "Copied rosa002evan01_01.xml to 17thcentury_files\n",
      "Copied gerr049besc01_01.xml to 17thcentury_files\n",
      "Copied laat004chri01_01.xml to 17thcentury_files\n",
      "Copied uile003chri03_01.xml to 17thcentury_files\n",
      "Copied koni001ieph01_01.xml to 17thcentury_files\n",
      "Copied groo126toon01_01.xml to 17thcentury_files\n",
      "Copied kemp001droe01_01.xml to 17thcentury_files\n",
      "Copied hoof001brie01_01.xml to 17thcentury_files\n",
      "Copied ridd012huys01_01.xml to 17thcentury_files\n",
      "Copied bata003nieu01_01.xml to 17thcentury_files\n",
      "Copied momm004brab03_01.xml to 17thcentury_files\n",
      "Copied smid018sinn01_01.xml to 17thcentury_files\n",
      "Copied scha001walc01_01.xml to 17thcentury_files\n",
      "Copied bred001rodd02_01.xml to 17thcentury_files\n",
      "Copied tell001vier01_01.xml to 17thcentury_files\n",
      "Copied suet001brus01_01.xml to 17thcentury_files\n",
      "Copied make001denl02_01.xml to 17thcentury_files\n",
      "Copied twis001kley01_01.xml to 17thcentury_files\n",
      "Copied come001port01_01.xml to 17thcentury_files\n",
      "Copied otho001poem01_01.xml to 17thcentury_files\n",
      "Copied heyn001bloe01_01.xml to 17thcentury_files\n",
      "Copied heus010chri02_01.xml to 17thcentury_files\n",
      "Copied kolm001nede01_01.xml to 17thcentury_files\n",
      "Copied harl003eeni01_01.xml to 17thcentury_files\n",
      "Copied veld030amst01_01.xml to 17thcentury_files\n",
      "Copied jans004zede01_01.xml to 17thcentury_files\n",
      "Copied barl001poem01_01.xml to 17thcentury_files\n",
      "Copied boey001nieu01_01.xml to 17thcentury_files\n",
      "Copied clae030rijp01_01.xml to 17thcentury_files\n",
      "Copied poir001heyl03_01.xml to 17thcentury_files\n",
      "Copied bred001chak02_01.xml to 17thcentury_files\n",
      "Copied brun001embl03_01.xml to 17thcentury_files\n",
      "Copied vinc009nieu02_01.xml to 17thcentury_files\n",
      "Copied merw001gees01_01.xml to 17thcentury_files\n",
      "Copied buss012ghee01_01.xml to 17thcentury_files\n",
      "Copied cost001isab01_01.xml to 17thcentury_files\n",
      "Copied hofm005nede02_01.xml to 17thcentury_files\n",
      "Copied leen001thea01_01.xml to 17thcentury_files\n",
      "Copied blas001fida01_01.xml to 17thcentury_files\n",
      "Copied pels017amst01_01.xml to 17thcentury_files\n",
      "Copied targ004haer01_01.xml to 17thcentury_files\n",
      "Copied poir001ydel01_01.xml to 17thcentury_files\n",
      "Copied jans004chri01_01.xml to 17thcentury_files\n",
      "Copied buys001astr01_01.xml to 17thcentury_files\n",
      "Copied prin015mede01_01.xml to 17thcentury_files\n",
      "Copied verm047rond02_01.xml to 17thcentury_files\n",
      "Copied ques002casi01_01.xml to 17thcentury_files\n",
      "Copied heem001inle01_01.xml to 17thcentury_files\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Create a set of base filenames (without extensions) for fast lookup\n",
    "file_list = set(filtered_df['ti_id'].dropna().unique())\n",
    "\n",
    "# Define source and destination folder paths\n",
    "source_folder = 'dbnl_xml'  # Update with the actual path of the XML files folder\n",
    "destination_folder = '17thcentury_files' # Update with the actual path for output\n",
    "\n",
    "# Ensure the destination folder exists\n",
    "os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "# Copy matching files from source to destination\n",
    "for filename in os.listdir(source_folder):\n",
    "    # Remove the .xml extension and any suffixes after an underscore\n",
    "    base_name = filename.split(\".xml\")[0].split(\"_\")[0]\n",
    "    \n",
    "    if base_name in file_list:\n",
    "        source_path = os.path.join(source_folder, filename)\n",
    "        destination_path = os.path.join(destination_folder, filename)\n",
    "        shutil.copy2(source_path, destination_path)\n",
    "        print(f\"Copied {filename} to {destination_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in 17thcentury_files: 320\n"
     ]
    }
   ],
   "source": [
    "num_files = len(os.listdir(destination_folder))\n",
    "print(f\"Number of files in {destination_folder}: {num_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/320 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 320/320 [00:00<00:00, 536.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory tulips created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 320/320 [00:10<00:00, 29.96it/s]\n"
     ]
    }
   ],
   "source": [
    "from dbnl_bear import parse\n",
    "\n",
    "# Ensure the parser instance is created (as in your initial code)\n",
    "parser = parse.DBNLParser()\n",
    "\n",
    "# Run the main parsing function\n",
    "parser.dbnl_to_txt(input_dir=\"17thcentury_files\", output_dir=\"tulips\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment v0.ariables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from langchain_openai import ChatOpenAI\n",
    "from tqdm.asyncio import tqdm\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field, create_model\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "def create_model_name(phenomenon_of_interest: str) -> str:\n",
    "    return ''.join(word.capitalize() for word in phenomenon_of_interest.split())\n",
    "\n",
    "def create_llm_analysis_model(phenomenon_of_interest: str) -> BaseModel:\n",
    "    \"\"\"\n",
    "    This model goes to the LLM. The difference here is that the original_sentence field is not present\n",
    "    as it would be a waste of resources to let the LLM do that.\n",
    "    \"\"\"\n",
    "    model_name = create_model_name(phenomenon_of_interest)\n",
    "    return create_model(\n",
    "        f\"{model_name}InText\",\n",
    "        explanation=(str, Field(description=f\"Explain whether the sentence contains information about {phenomenon_of_interest}\")),\n",
    "        judgement=(bool, Field(description=f\"Whether the sentence contains information about {phenomenon_of_interest}\"))\n",
    "    )\n",
    "\n",
    "\n",
    "def create_full_analysis_model(phenomenon_of_interest: str) -> BaseModel:\n",
    "    \"\"\"\n",
    "    This model is the same as the llm_analysis_model but with the original sentence field added.\n",
    "    \"\"\"\n",
    "    model_name = create_model_name(phenomenon_of_interest)\n",
    "    return create_model(\n",
    "        f\"{model_name}InText\",\n",
    "        explanation=(str, Field(description=f\"Explain whether the sentence contains information about {phenomenon_of_interest}\")),\n",
    "        judgement=(bool, Field(description=f\"Whether the sentence contains information about {phenomenon_of_interest}\")),\n",
    "        original_sentence=(str, Field(description=\"The original sentence from the document\"))\n",
    "    )\n",
    "\n",
    "def get_system_prompt(phenomenon_of_interest: str) -> str:\n",
    "    return f\"\"\"I am a Cultural Historian and Literary Scholar interested in  {phenomenon_of_interest}. Your task is to read sentences in Early Modern Dutch and indicate whether, \n",
    "    given my research interest, the sentence is relevant to my research. You should provide a clear explanation, a boolean judgement, and details about\n",
    "    {phenomenon_of_interest} if present.\"\"\"\n",
    "\n",
    "async def analyze_document(input_file: str, phenomenon_of_interest: str, text_splitter=text_splitter,\n",
    "                           model=\"gpt-4o-mini-2024-07-18\", max_fragment_tasks=10):\n",
    "\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        original_text = f.read()\n",
    "\n",
    "    sentences = text_splitter.split_text(original_text)\n",
    "\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise ValueError(\"API key not found. Install python-dotenv, make .env style and save the API key there as: OPENAI_API_KEY=your-api-key-here\")\n",
    "\n",
    "    llm = ChatOpenAI(model=model)\n",
    "    LLMAnalysisModel = create_llm_analysis_model(phenomenon_of_interest)\n",
    "    FullAnalysisModel = create_full_analysis_model(phenomenon_of_interest)\n",
    "\n",
    "    llm_structured_output = llm.with_structured_output(LLMAnalysisModel)\n",
    "\n",
    "    system_prompt = get_system_prompt(phenomenon_of_interest)\n",
    "    prompt = ChatPromptTemplate.from_messages([(\"system\", system_prompt), (\"human\", \"{input}\")])\n",
    "    structured_llm = prompt | llm_structured_output\n",
    "\n",
    "    # Semaphore to limit concurrent fragment processing\n",
    "    sem = asyncio.Semaphore(max_fragment_tasks)\n",
    "\n",
    "    async def process_fragment(sentence):\n",
    "        async with sem:\n",
    "            return await analyze_sentence(sentence, structured_llm, FullAnalysisModel)\n",
    "\n",
    "    tasks = [process_fragment(sentence) for sentence in sentences]\n",
    "\n",
    "    # Use tqdm for progress tracking\n",
    "    return await tqdm.gather(*tasks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started with houw001para01.txt\n",
      "started with zasy001borg01.txt\n",
      "started with ampz001besc01.txt\n",
      "started with hoof002jans02.txt\n",
      "started with nieu001soph03.txt\n",
      "started with born006gees01.txt\n",
      "started with aker002clee01.txt\n",
      "started with bors001denb01.txt\n",
      "started with koni001acha01.txt\n",
      "started with breu004cupi01.txt\n",
      "started with nier007opre01.txt\n",
      "started with momm004brab02.txt\n",
      "started with goed012meta01.txt\n",
      "started with cats001maec01.txt\n",
      "started with fort007gees01.txt\n",
      "started with zach001bruy01.txt\n",
      "started with rula001saty01.txt\n",
      "started with hond001dape02.txt\n",
      "started with smid018sinn01.txt\n",
      "started with krul001amst01.txt\n",
      "started with brug061chri01.txt\n",
      "started with uile003chri03.txt\n",
      "started with vrol014matr01.txt\n",
      "started with harm001suyv01.txt\n",
      "started with vaer010haar01.txt\n",
      "started with rode001casa01.txt\n",
      "started with oost026ryme01.txt\n",
      "started with dyck014oude01.txt\n",
      "started with vict001goli01.txt\n",
      "started with else006lacc01.txt\n",
      "started with goos015nieu01.txt\n",
      "started with lope001dull01.txt\n",
      "started with dubb003heli01.txt\n",
      "started with vaen001quin01.txt\n",
      "started with loem001ghee01.txt\n",
      "started with ocke003heme01.txt\n",
      "started with heyn001bloe01.txt\n",
      "started with tell001vier01.txt\n",
      "started with hard001godd01.txt\n",
      "started with hein001cont01.txt\n",
      "started with leen001thea01.txt\n",
      "started with brun001prov01.txt\n",
      "started with buit010bloe01.txt\n",
      "started with crus001epig01.txt\n",
      "started with clae030rijp01.txt\n",
      "started with harl003eeni01.txt\n",
      "started with krul001eerl01.txt\n",
      "started with baud004edip01.txt\n",
      "started with ooij001haer01.txt\n",
      "started with bosc015poet01.txt\n",
      "started with scha001spel01.txt\n",
      "started with gera044sedi01.txt\n",
      "started with cats001houw01.txt\n",
      "started with grie003spre01.txt\n",
      "started with maer005stic01.txt\n",
      "started with heem007nede01.txt\n",
      "started with sout002nvch01.txt\n",
      "started with bols002duyf02.txt\n",
      "started with oost026gelo01.txt\n",
      "started with rode001keys02.txt\n",
      "started with poir001pelg01.txt\n",
      "started with swam001hist01.txt\n",
      "started with vaen001embl01.txt\n",
      "started with mand001guld02.txt\n",
      "started with heem001inle01.txt\n",
      "started with brun004davi01.txt\n",
      "started with come001port01.txt\n",
      "started with leeu035chri01.txt\n",
      "started with suet001brus01.txt\n",
      "started with boey001nieu01.txt\n",
      "started with vond001jose05.txt\n",
      "started with scep002oude01.txt\n",
      "started with vond001pasc02.txt\n",
      "started with vond001pete01.txt\n",
      "started with scha001walc01.txt\n",
      "started with barl001poem01.txt\n",
      "started with smid018minn01.txt\n",
      "started with buss012ghee01.txt\n",
      "started with bode001goud01.txt\n",
      "started with star001dara02.txt\n",
      "started with koer001bloe01.txt\n",
      "started with star001timb01.txt\n",
      "started with hoof001hend02.txt\n",
      "started with gerr003nieu01.txt\n",
      "started with bien002prof02.txt\n",
      "started with krul001verm01.txt\n",
      "started with hout009test01.txt\n",
      "started with rhij002vreu04.txt\n",
      "started with make001troo02.txt\n",
      "started with mayv001scha01.txt\n",
      "started with goed012meta02.txt\n",
      "started with twis001kley01.txt\n",
      "started with rosa002evan01.txt\n",
      "started with swae006sing03.txt\n",
      "started with veld030amst01.txt\n",
      "started with camp001stic02.txt\n",
      "started with duis001echt01.txt\n",
      "started with rode001keys03.txt\n",
      "started with make001scha02.txt\n",
      "started with plat001dord01.txt\n",
      "started with juni001schi01.txt\n",
      "started with wits010stic02.txt\n",
      "started with heus010chri02.txt\n",
      "started with mech003cloo01.txt\n",
      "started with koni001ieph01.txt\n",
      "started with putm012putm01.txt\n",
      "started with hame003jour01.txt\n",
      "started with haef001lust01.txt\n",
      "started with huyg001mome02.txt\n",
      "started with ruys008flor01.txt\n",
      "started with borc002brus01.txt\n",
      "started with veen033kroo01.txt\n",
      "started with jonc006hede01.txt\n",
      "started with veen010over01.txt\n",
      "started with camp001stic01.txt\n",
      "started with mayv001verm01.txt\n",
      "started with mule001heme01.txt\n",
      "started with teyl001devo01.txt\n",
      "started with wesb002haer01.txt\n",
      "started with krul001rosi01.txt\n",
      "started with houw001deng01.txt\n",
      "started with rode001rodo01.txt\n",
      "started with ques002lauw01.txt\n",
      "started with roch007natu01.txt\n",
      "started with swae006sing01.txt\n",
      "started with goid001chro01.txt\n",
      "started with meer040como01.txt\n",
      "started with rhij002vreu02.txt\n",
      "started with stri015chao01.txt\n",
      "started with bosc015kons01.txt\n",
      "started with nieu001salo01.txt\n",
      "started with lixb001heme02.txt\n",
      "started with quin005holl01.txt\n",
      "started with brun001davi01.txt\n",
      "started with donc007besc01.txt\n",
      "started with drie002ench01.txt\n",
      "started with smet025oude01.txt\n",
      "started with gabb001lykt01.txt\n",
      "started with goed012meta03.txt\n",
      "started with ridd012huys01.txt\n",
      "started with poir001ydel01.txt\n",
      "started with orle001vers01.txt\n",
      "started with rode001hert01.txt\n",
      "started with poir001afbe01.txt\n",
      "started with fran115grou01.txt\n",
      "started with sent002nieu01.txt\n",
      "started with kolm001leve01.txt\n",
      "started with over001psal01.txt\n",
      "started with veen010zinn01.txt\n",
      "started with sucq002wech01.txt\n",
      "started with bred001gees01.txt\n",
      "started with stey002geve01.txt\n",
      "started with gerr049besc01.txt\n",
      "started with meij001lmei01.txt\n",
      "started with mand001beth01.txt\n",
      "started with cloc001groo02.txt\n",
      "started with jans004zede01.txt\n",
      "started with vond001elek01.txt\n",
      "started with bred001chak02.txt\n",
      "started with zeve001poem01.txt\n",
      "started with gilb007lief01.txt\n",
      "started with eras001kers03.txt\n",
      "started with merw001uyth01.txt\n",
      "started with heyn003wegw01.txt\n",
      "started with rode001keys01.txt\n",
      "started with stal001extr01.txt\n",
      "started with kerc001vand01.txt\n",
      "started with bolo001ghee01.txt\n",
      "started with burg016gere02.txt\n",
      "started with vrie047uytg01.txt\n",
      "started with nieu001clau01.txt\n",
      "started with para003prin02.txt\n",
      "started with nieu001aegy01.txt\n",
      "started with soet007kley01.txt\n",
      "started with baud002afbe01.txt\n",
      "started with nieu001jeru01.txt\n",
      "started with targ004haer01.txt\n",
      "started with ques002casi01.txt\n",
      "started with vond001gysb04.txt\n",
      "started with gouw004erat01.txt\n",
      "started with brun001gron01.txt\n",
      "started with stal001evan01.txt\n",
      "started with jenn003ghee01.txt\n",
      "started with vond001hier01.txt\n",
      "started with ampz001nasz01.txt\n",
      "started with kalb001muli01.txt\n",
      "started with breu004lust01.txt\n",
      "started with clae030rijp02.txt\n",
      "started with krul001vonn01.txt\n",
      "started with stal001guld02.txt\n",
      "started with hugo001piad01.txt\n",
      "started with vivr001dial02.txt\n",
      "started with heem001pubo01.txt\n",
      "started with roel018biro03.txt\n",
      "started with eemb001haer01.txt\n",
      "started with vinc009nieu02.txt\n",
      "started with gelr003triu01.txt\n",
      "started with stal001heme01.txt\n",
      "started with spey001syon02.txt\n",
      "started with cats001trou01.txt\n",
      "started with brun001clda01.txt\n",
      "started with zoet001parn01.txt\n",
      "started with samb001gees01.txt\n",
      "started with laat004chri01.txt\n",
      "started with meer017gees01.txt\n",
      "started with bred001rodd02.txt\n",
      "started with koni001sims01.txt\n",
      "started with hoof001embl02.txt\n",
      "started with cole001nieu01.txt\n",
      "started with camp001uytb01.txt\n",
      "started with cour001inte01.txt\n",
      "started with mijl001ling01.txt\n",
      "started with hard001godd02.txt\n",
      "started with revi001clps01.txt\n",
      "started with kolm001batt01.txt\n",
      "started with bors001stra01.txt\n",
      "started with vena001vert01.txt\n",
      "started with font031ario01.txt\n",
      "started with carp002verh01.txt\n",
      "started with cats001klag01.txt\n",
      "started with hoof001brie01.txt\n",
      "started with momm004brab03.txt\n",
      "started with ling001apol01.txt\n",
      "started with make001denh01.txt\n",
      "started with sonn003basu01.txt\n",
      "started with groo126toon01.txt\n",
      "started with leuv001amor01.txt\n",
      "started with hofm005nede02.txt\n",
      "started with poir001heyl03.txt\n",
      "started with elst005ghee01.txt\n",
      "started with ampz001rijm01.txt\n",
      "started with cole001lust01.txt\n",
      "started with buys001astr01.txt\n",
      "started with stal001room01.txt\n",
      "started with bred001spaa09.txt\n",
      "started with thie008scha01.txt\n",
      "started with scho188embl01.txt\n",
      "started with pute001comu01.txt\n",
      "started with vond001pala01.txt\n",
      "started with verl023amst01.txt\n",
      "started with wael001brvy01.txt\n",
      "started with joos025groo01.txt\n",
      "started with groo001chri03.txt\n",
      "started with make001denl02.txt\n",
      "started with magi007kooc02.txt\n",
      "started with boxh002embl02.txt\n",
      "started with leuv001thea01.txt\n",
      "started with blas001fida01.txt\n",
      "started with vond001luci01.txt\n",
      "started with pels017tlof01.txt\n",
      "started with heyn003embl03.txt\n",
      "started with dros028scho01.txt\n",
      "started with bien002hand01.txt\n",
      "started with baud002morg01.txt\n",
      "started with nieu001livi01.txt\n",
      "started with brun002wets01.txt\n",
      "started with beve001scha01.txt\n",
      "started with jonc006rose01.txt\n",
      "started with brun001embl02.txt\n",
      "started with kolm001nede01.txt\n",
      "started with poir001duyf01.txt\n",
      "started with star001drie01.txt\n",
      "started with brun001embl03.txt\n",
      "started with gerr049hist01.txt\n",
      "started with cost001isab01.txt\n",
      "started with eemb001soph01.txt\n",
      "started with bata003nieu01.txt\n",
      "started with ampz001hoog01.txt\n",
      "started with yser001triu01.txt\n",
      "started with prin015mede01.txt\n",
      "started with ampz001west01.txt\n",
      "started with boel009onee01.txt\n",
      "started with vinc009nieu01.txt\n",
      "started with vond001maeg04.txt\n",
      "started with koer001tnie01.txt\n",
      "started with merw001gees01.txt\n",
      "started with poll013bruy01.txt\n",
      "started with bour004desw01.txt\n",
      "started with popp007hist01.txt\n",
      "started with heyn003embl01.txt\n",
      "started with camp001drka01.txt\n",
      "started with vaen001amor02.txt\n",
      "started with jaco009scha01.txt\n",
      "started with pass004spie01.txt\n",
      "started with mech003ghee01.txt\n",
      "started with vlee002ryme01.txt\n",
      "started with brau007scha01.txt\n",
      "started with ampz001klae01.txt\n",
      "started with verm047rond01.txt\n",
      "started with fyne001kley01.txt\n",
      "started with rode001egle01.txt\n",
      "started with stal001vrou01.txt\n",
      "started with lubb003lijd01.txt\n",
      "started with smid018lyde02.txt\n",
      "started with west001nieu01.txt\n",
      "started with hoof002styv01.txt\n",
      "started with jans004chri01.txt\n",
      "started with baro004leyt01.txt\n",
      "started with otho001poem01.txt\n",
      "started with vloe003ghee01.txt\n",
      "started with verm047rond02.txt\n",
      "started with fore024refe01.txt\n",
      "started with haef004para02.txt\n",
      "started with orle001besc01.txt\n",
      "started with noot008jeug01.txt\n",
      "started with hani001beve01.txt\n",
      "started with well004verm01.txt\n",
      "started with pels017amst01.txt\n",
      "started with hube012psal01.txt\n",
      "started with west001davi01.txt\n",
      "started with beer014ghee01.txt\n",
      "started with deut002kley01.txt\n",
      "started with slui006psal01.txt\n",
      "started with haef001scho01.txt\n",
      "started with nieu001saul01.txt\n",
      "started with nieu001poem01.txt\n",
      "started with haer002lied01.txt\n",
      "started with cats001sile01.txt\n",
      "started with kemp001droe01.txt\n",
      "started with hard001denv01.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1326 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AException ignored in: <function Task.__del__ at 0x7fa7ccac3c40>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 142, in __del__\n",
      "    super().__del__()\n",
      "  File \"/usr/lib/python3.11/asyncio/futures.py\", line 91, in __del__\n",
      "    def __del__(self):\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "\n",
    "# Directory to save individual output files\n",
    "output_dir = \"output_relevant_passages\"\n",
    "os.makedirs(output_dir, exist_ok=True)  # Create output directory if it doesn't exist\n",
    "\n",
    "\n",
    "async def process_file(filename):\n",
    "    path = \"tulips/\" + filename\n",
    "    result = await asyncio.wait_for(ai_read.analyze_document(path, \"tulips\"), timeout=120)\n",
    "    relevant_passages = [e.original_sentence for e in result if e.judgement]\n",
    "    if relevant_passages:\n",
    "        output_file_path = os.path.join(output_dir, f\"{filename}_relevant.txt\")\n",
    "        with open(output_file_path, \"w\", encoding=\"utf-8\") as outfile:\n",
    "            for passage in relevant_passages:\n",
    "                outfile.write(f\"{passage}\\n\")\n",
    "    else:\n",
    "            print(f\"No relevant passages found in file {filename}\")\n",
    "                \n",
    "async def main():\n",
    "    tasks = []\n",
    "    for filename in os.listdir(\"tulips\"):\n",
    "        tasks.append(process_file(filename))\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in tulips: 320\n",
      "Total number of words in all text files: 14533127\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Count the number of files in the 17thcentury_files folder\n",
    "num_files = len(os.listdir('tulips'))\n",
    "print(f\"Number of files in tulips: {num_files}\")\n",
    "\n",
    "# Count the number of words in all text files together\n",
    "total_word_count = 0\n",
    "\n",
    "for filename in os.listdir('tulips'):\n",
    "    file_path = os.path.join('tulips', filename)\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "        words = text.split()\n",
    "        total_word_count += len(words)\n",
    "\n",
    "print(f\"Total number of words in all text files: {total_word_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in all relevant passages: 23618\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Initialize total word count\n",
    "total_word_count_relevant_passages = 0\n",
    "\n",
    "# Iterate through each file in the output_relevant_passages folder\n",
    "for filename in os.listdir('../output_relevant_passages'):\n",
    "    file_path = os.path.join('../output_relevant_passages', filename)\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "        words = text.split()\n",
    "        total_word_count_relevant_passages += len(words)\n",
    "\n",
    "print(f\"Total number of words in all relevant passages: {total_word_count_relevant_passages}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in ../output_relevant_passages: 144\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Count the number of files in the ../output_relevant_passages folder\n",
    "num_files_relevant_passages = len(os.listdir('../output_relevant_passages'))\n",
    "print(f\"Number of files in ../output_relevant_passages: {num_files_relevant_passages}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
